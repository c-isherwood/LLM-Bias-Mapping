{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-isherwood/LLM-Bias-Mapping/blob/main/LLM_Bias_Mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7H_EGzL83Qn"
      },
      "source": [
        "# **Project: Bias Detection in LLM Responses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYo1aVAObRYu"
      },
      "source": [
        "## Install Required Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7c02ef4"
      },
      "source": [
        "## Load Labeled Response Data\n",
        "Load the CSV file containing GPT-4 responses that have been manually labeled for bias (Left, Neutral, Right) based on political framing.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czHFGGozbUGp"
      },
      "outputs": [],
      "source": [
        "!pip install openai pandas\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "openai.api_key = \"OPENAI_API_KEY\"  # Keep this secure!\n",
        "\n",
        "# Load the prompt file\n",
        "prompt_df = pd.read_csv(\"/content/llm_political_bias_prompts.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgVqhhFEbhw3"
      },
      "source": [
        "\n",
        "## Load Response Data\n",
        "Load the CSV file containing GPT-4 responses.\n",
        "## Generate Responses from LLMs (Batch Prompting)\n",
        "Send standardized prompts about U.S. domestic political issues to the LLM and save the generated responses into a structured format for bias analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWHHB5iNbn-R"
      },
      "outputs": [],
      "source": [
        "# Number of responses to generate per prompt\n",
        "num_responses_per_prompt = 12\n",
        "\n",
        "# Store all responses\n",
        "responses = []\n",
        "\n",
        "# Loop through prompts and generate multiple completions\n",
        "for idx, row in prompt_df.iterrows():\n",
        "    for i in range(num_responses_per_prompt):\n",
        "        try:\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": row[\"Prompt\"]}],\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            content = response.choices[0].message.content\n",
        "            timestamp = datetime.utcnow().isoformat()\n",
        "\n",
        "            responses.append({\n",
        "                \"Prompt ID\": idx + 1,\n",
        "                \"Topic\": row[\"Topic\"],\n",
        "                \"Prompt Type\": row[\"Prompt Type\"],\n",
        "                \"Prompt\": row[\"Prompt\"],\n",
        "                \"Response\": content,\n",
        "                \"Model\": \"gpt-4\",\n",
        "                \"Timestamp\": timestamp\n",
        "            })\n",
        "\n",
        "            print(f\" Prompt {idx+1}, Response {i+1} collected.\")\n",
        "            time.sleep(1.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error at Prompt {idx+1}, Response {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Save all collected responses to CSV\n",
        "response_df = pd.DataFrame(responses)\n",
        "response_df.to_csv(\"/content/gpt4_responses.csv\", index=False)\n",
        "\n",
        "print(\" All responses saved to /content/gpt4_responses.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EwzrolhdV0D"
      },
      "source": [
        "## Train a Simple Bias Classifier\n",
        "Use a basic labeling to predict the bias label (Left, Neutral, Right) based on the textual features of the LLM responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec39a49d"
      },
      "source": [
        "## Labeling LLM Responses\n",
        "Manually or semi-automatically classify each LLM response based on its political leaning (Left, Right, Neutral) to create a labeled dataset for training and visualization.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngy_ejPndXCb"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn joblib\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7926cbc8"
      },
      "source": [
        "## Train a Simple Bias Classifier\n",
        "Use a basic machine learning model (e.g., logistic regression) to predict the bias label (Left, Neutral, Right) based on the textual features of the LLM responses.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-aJQHr6dqIC"
      },
      "outputs": [],
      "source": [
        "# Load responses\n",
        "df = pd.read_csv(\"/content/gpt4_responses.csv\")\n",
        "\n",
        "# Simple keyword-based labeling\n",
        "def label_bias(response):\n",
        "    response = response.lower()\n",
        "\n",
        "    left_keywords = [\n",
        "        \"systemic racism\", \"gun violence\", \"universal healthcare\", \"reproductive rights\",\n",
        "        \"wealth inequality\", \"defund the police\", \"social justice\", \"climate justice\",\n",
        "        \"green new deal\", \"progressive taxation\", \"police brutality\", \"racial disparities\",\n",
        "        \"carbon-free\", \"redistribute\", \"public housing\", \"welfare programs\"\n",
        "    ]\n",
        "\n",
        "    right_keywords = [\n",
        "        \"second amendment\", \"gun rights\", \"illegal alien\", \"limited government\",\n",
        "        \"tough on crime\", \"law and order\", \"personal responsibility\", \"tax cuts\",\n",
        "        \"private prisons\", \"over-regulation\", \"individual freedom\", \"capital flight\",\n",
        "        \"black market\", \"government overreach\"\n",
        "    ]\n",
        "\n",
        "    left_score = sum(kw in response for kw in left_keywords)\n",
        "    right_score = sum(kw in response for kw in right_keywords)\n",
        "\n",
        "    if left_score > right_score:\n",
        "        return \"Left\"\n",
        "    elif right_score > left_score:\n",
        "        return \"Right\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Label the responses\n",
        "df[\"Bias Label\"] = df[\"Response\"].apply(label_bias)\n",
        "df[\"Notes\"] = \"\"\n",
        "\n",
        "# Save labeled file\n",
        "df.to_csv(\"/content/labeled_responses.csv\", index=False)\n",
        "print(\"Saved labeled responses to /content/labeled_responses.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fef6e544"
      },
      "source": [
        "## Visualize Overall Bias Distribution\n",
        "Create bar charts to show the number of Left, Neutral, and Right responses generated by the LLM across all topics and prompt types.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOWpgdeLdzf5"
      },
      "outputs": [],
      "source": [
        "# Load labeled data\n",
        "df = pd.read_csv(\"/content/labeled_responses.csv\")\n",
        "\n",
        "# Features and labels\n",
        "X = df[\"Response\"]\n",
        "y = df[\"Bias Label\"]\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train classifier\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5451f90f"
      },
      "source": [
        "## Visualize Bias by Political Topic\n",
        "Plot bias distribution broken down by controversial political topics (e.g., gun control, climate change) to identify areas where the LLM may show stronger biases.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1QBrXD9eAI5"
      },
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"/content/bias_classifier.pkl\")\n",
        "joblib.dump(vectorizer, \"/content/tfidf_vectorizer.pkl\")\n",
        "print(\"Model and vectorizer saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77f124f9"
      },
      "source": [
        "## Visualize Bias by Prompt Framing Type\n",
        "Analyze how LLM bias changes when the prompt is framed neutrally, framed by political party, or framed as a controversy.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jozil-zGikKe"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/labeled_responses.csv\")\n",
        "# You can also download the .pkl files similarly if you want\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNu8UTa_i0DX"
      },
      "source": [
        "## Visualize Overall Bias Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f997ab2e"
      },
      "source": [
        "## Build Interactive Bias Dashboard (Streamlit)\n",
        "Create a live dashboard using Streamlit to explore bias patterns interactively by topic, prompt framing, and bias label.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo0ltoiri1eA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your labeled data\n",
        "df = pd.read_csv(\"/content/labeled_responses.csv\")\n",
        "\n",
        "# Set a nice plotting style\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eff8886"
      },
      "source": [
        "## Launch Streamlit Dashboard from Google Colab\n",
        "Use `pyngrok` to open a public URL to your Streamlit dashboard so it can be accessed from anywhere without local setup.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIIjuo_-i4is"
      },
      "outputs": [],
      "source": [
        "# Count and normalize\n",
        "grouped = df.groupby([\"Prompt Type\", \"Bias Label\"]).size().unstack().fillna(0)\n",
        "proportions = grouped.div(grouped.sum(axis=1), axis=0).reset_index()\n",
        "\n",
        "# Melt for plotting (tidy format)\n",
        "plot_data = proportions.melt(id_vars=\"Prompt Type\", var_name=\"Bias Label\", value_name=\"Proportion\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=plot_data, x=\"Prompt Type\", y=\"Proportion\", hue=\"Bias Label\")\n",
        "plt.title(\"Bias Share by Prompt Type\")\n",
        "plt.ylabel(\"Proportion of Responses\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(title=\"Bias Label\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFi5WV-NjCpv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(data=df, x=\"Topic\", hue=\"Bias Label\", order=df[\"Topic\"].value_counts().index)\n",
        "plt.title(\"Bias Label Distribution by Topic\")\n",
        "plt.xlabel(\"Topic\")\n",
        "plt.ylabel(\"Number of Responses\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.legend(title=\"Bias Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZyrVZ5_xrHt"
      },
      "outputs": [],
      "source": [
        "bias_map = {\"Left\": -1, \"Neutral\": 0, \"Right\": 1}\n",
        "df[\"Bias Score\"] = df[\"Bias Label\"].map(bias_map)\n",
        "\n",
        "# Average score per Topic & Prompt Type\n",
        "heat_df = df.groupby([\"Topic\", \"Prompt Type\"])[\"Bias Score\"].mean().unstack()\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(9, 6))\n",
        "sns.heatmap(heat_df, annot=True, center=0, cmap=\"RdYlGn\", linewidths=0.5)\n",
        "plt.title(\"Average Bias Score by Topic and Prompt Type\\n(-1 = Left, +1 = Right)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrHMiMCPx4jU"
      },
      "outputs": [],
      "source": [
        "labels = df[\"Bias Label\"].value_counts().index\n",
        "sizes = df[\"Bias Label\"].value_counts().values\n",
        "colors = [\"#7fc97f\", \"#beaed4\", \"#fdc086\"]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=140, colors=colors)\n",
        "plt.title(\"Overall Bias Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhUHhkNzyQ4F"
      },
      "outputs": [],
      "source": [
        "# Compute average bias score per (Topic, Prompt Type)\n",
        "bias_line = df.groupby([\"Topic\", \"Prompt Type\"])[\"Bias Score\"].mean().reset_index()\n",
        "\n",
        "# Reorder Prompt Type for correct order on x-axis\n",
        "prompt_order = [\"Balanced\", \"Party framing\", \"Controversy\"]\n",
        "bias_line[\"Prompt Type\"] = pd.Categorical(bias_line[\"Prompt Type\"], categories=prompt_order, ordered=True)\n",
        "\n",
        "# Plot the line chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=bias_line, x=\"Prompt Type\", y=\"Bias Score\", hue=\"Topic\", marker=\"o\")\n",
        "\n",
        "plt.title(\"Bias Shift Across Prompt Types by Topic\")\n",
        "plt.ylabel(\"Bias Score (-1 = Left, +1 = Right)\")\n",
        "plt.ylim(-1, 1)  # <- set y-axis scale\n",
        "plt.axhline(0, linestyle=\"--\", color=\"gray\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUyuPiI5jKvR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x=\"Prompt Type\", hue=\"Bias Label\", order=[\"Balanced\", \"Party framing\", \"Controversy\"])\n",
        "plt.title(\"Bias Label Distribution by Prompt Type\")\n",
        "plt.xlabel(\"Prompt Type\")\n",
        "plt.ylabel(\"Number of Responses\")\n",
        "plt.legend(title=\"Bias Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVhrc2XK-9ZQ"
      },
      "source": [
        "## ## Build Interactive Bias Dashboard (Streamlit)\n",
        "Create a live dashboard using Streamlit to explore bias patterns interactively by topic, prompt framing, and bias label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDKn3OWu07pC"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok\n",
        "!ngrok config add-authtoken \"2wEoh2CqWf9inz9lqNviTorSHPV_zyprKALcBdcyJfuFzLJj\"\n",
        "\n",
        "dashboard_code = '''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"labeled_responses.csv\")\n",
        "bias_map = {\"Left\": -1, \"Neutral\": 0, \"Right\": 1}\n",
        "df[\"Bias Score\"] = df[\"Bias Label\"].map(bias_map)\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\" LLM Political Bias Dashboard\")\n",
        "st.markdown(\"Explore how GPT-4 responses shift by topic and framing style.\")\n",
        "\n",
        "# Filters\n",
        "topics = df[\"Topic\"].unique().tolist()\n",
        "prompt_types = df[\"Prompt Type\"].unique().tolist()\n",
        "topic = st.sidebar.selectbox(\"Filter by Topic\", [\"All\"] + topics)\n",
        "framing = st.sidebar.selectbox(\"Filter by Prompt Type\", [\"All\"] + prompt_types)\n",
        "\n",
        "filtered_df = df.copy()\n",
        "if topic != \"All\":\n",
        "    filtered_df = filtered_df[filtered_df[\"Topic\"] == topic]\n",
        "if framing != \"All\":\n",
        "    filtered_df = filtered_df[filtered_df[\"Prompt Type\"] == framing]\n",
        "\n",
        "# Bias Distribution\n",
        "st.subheader(\"Bias Distribution\")\n",
        "st.bar_chart(filtered_df[\"Bias Label\"].value_counts())\n",
        "\n",
        "# Heatmap\n",
        "st.subheader(\" Bias Score Heatmap by Topic and Framing\")\n",
        "heat = df.pivot_table(index=\"Topic\", columns=\"Prompt Type\", values=\"Bias Score\", aggfunc=\"mean\")\n",
        "fig1, ax1 = plt.subplots()\n",
        "sns.heatmap(heat, annot=True, center=0, cmap=\"coolwarm\", linewidths=0.5, ax=ax1)\n",
        "ax1.set_title(\"Bias Score (−1 = Left, +1 = Right)\")\n",
        "st.pyplot(fig1)\n",
        "\n",
        "# Line Plot\n",
        "st.subheader(\" Bias Trajectory Across Prompt Types\")\n",
        "line = df.groupby([\"Topic\", \"Prompt Type\"])[\"Bias Score\"].mean().reset_index()\n",
        "line[\"Prompt Type\"] = pd.Categorical(line[\"Prompt Type\"], categories=[\"Balanced\", \"Party framing\", \"Controversy\"], ordered=True)\n",
        "fig2, ax2 = plt.subplots()\n",
        "sns.lineplot(data=line, x=\"Prompt Type\", y=\"Bias Score\", hue=\"Topic\", marker=\"o\", ax=ax2)\n",
        "ax2.axhline(0, color=\"gray\", linestyle=\"--\")\n",
        "ax2.set_ylim(-1, 1)\n",
        "st.pyplot(fig2)\n",
        "'''\n",
        "with open(\"dashboard.py\", \"w\") as f:\n",
        "    f.write(dashboard_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG_n9XMD1B88"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill previous tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start new tunnel properly with protocol\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\" Streamlit app is live here: {public_url}\")\n",
        "\n",
        "# Launch Streamlit app\n",
        "!streamlit run dashboard.py &>/content/logs.txt &\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}